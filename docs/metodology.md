# Methodology

## Overview

This project proposes a non-invasive intelligent system for monitoring
microalgae growth phases using multimodal data fusion and machine
learning. The methodology integrates:

-   Image-based feature extraction (RGB computer vision)
-   Environmental sensing (temperature and pH)
-   Multimodal feature fusion
-   Neural network classification
-   Embedded edge deployment on microcontroller hardware

The complete workflow follows an experimental--computational pipeline
designed for reproducibility.

------------------------------------------------------------------------

## 1. System Architecture

The system is composed of four main layers:

1.  **Physical acquisition layer**
    -   Tubular vertical photobioreactor
    -   Controlled illumination
    -   Air injection system
    -   Temperature monitoring
2.  **Sensor and acquisition layer**
    -   RGB image capture
    -   Environmental sensors
    -   ESP32 microcontroller for synchronization
3.  **Processing layer**
    -   Image preprocessing
    -   Feature extraction
    -   Multimodal dataset construction
4.  **Inference layer**
    -   Neural network classification
    -   Edge deployment with quantized model

------------------------------------------------------------------------

## 2. Experimental Data Acquisition

### 2.1 Culture System

Microalgae cultures were grown inside a custom-built photobioreactor
designed to provide:

-   Controlled illumination
-   Stable temperature conditions
-   Continuous aeration
-   Non-invasive monitoring

Data collection was conducted over multiple cultivation cycles spanning
several weeks.

### 2.2 Multimodal Acquisition

Each sample contains:

-   RGB image of the culture
-   Temperature measurement
-   pH measurement
-   Timestamp synchronization

Data acquisition was automated to ensure temporal consistency.

------------------------------------------------------------------------

## 3. Image Preprocessing Pipeline

Images undergo a deterministic preprocessing workflow:

1.  Fixed camera configuration
2.  Region of Interest (ROI) extraction
3.  RGB normalization
4.  Noise reduction (smoothing)
5.  Statistical descriptor computation

Extracted visual features include:

-   Mean intensity per RGB channel
-   Standard deviation per channel
-   Luminance estimation

This produces numerical descriptors robust to illumination variability.

------------------------------------------------------------------------

## 4. Environmental Signal Processing

Environmental variables are preprocessed independently:

-   Outlier filtering
-   Temporal alignment with images
-   Normalization

Environmental features are later fused with visual descriptors.

------------------------------------------------------------------------

## 5. Multimodal Feature Vector Construction

A unified feature vector is generated by concatenating:

\[Visual Features \| Environmental Features\]

Resulting dataset characteristics:

-   Multidimensional numerical representation
-   Synchronized measurements
-   Supervised labels corresponding to growth phases

Growth phases:

-   Lag phase
-   Exponential phase
-   Stationary phase

Labeling was performed using hybrid experimental criteria combining
biological observation and temporal evolution.

------------------------------------------------------------------------

## 6. Dataset Preparation

The dataset was divided into:

-   Training set
-   Validation set
-   Test set

Stratified partitioning was applied to preserve class distribution.

Normalization parameters were computed exclusively from the training
subset to avoid data leakage.

------------------------------------------------------------------------

## 7. Neural Network Model

### 7.1 Architecture

A Multilayer Perceptron (MLP) was selected due to:

-   Low computational cost
-   Compatibility with embedded deployment
-   Strong performance on tabular multimodal data

Typical structure:

-   Fully connected dense layers
-   Nonlinear activation functions
-   Dropout during training

### 7.2 Training Configuration

Training procedure:

-   Supervised learning
-   Cross-entropy loss
-   Adam optimizer
-   Multiple independent runs for robustness evaluation

Evaluation metrics:

-   Accuracy
-   Precision
-   Recall
-   F1-score (macro average)

------------------------------------------------------------------------

## 8. Robustness Evaluation

Model robustness was evaluated using controlled perturbations:

-   Gaussian noise
-   Illumination variation
-   Blur effects
-   ROI displacement
-   Artificial artifacts

This stage simulates real operating conditions in biological systems.

------------------------------------------------------------------------

## 9. Embedded Deployment (Edge AI)

### 9.1 Model Optimization

The trained model was converted and optimized through:

1.  TensorFlow Lite conversion
2.  INT8 quantization
3.  Memory footprint reduction

### 9.2 Microcontroller Implementation

Deployment target:

-   ESP32 microcontroller

Embedded pipeline:

1.  Sensor acquisition
2.  Feature computation
3.  Local inference
4.  Real-time classification output

This enables autonomous operation without cloud dependency.

------------------------------------------------------------------------

## 10. Reproducibility Pipeline

The complete workflow can be reproduced using:

1.  Dataset acquisition scripts
2.  Feature extraction modules
3.  Training notebooks
4.  Model conversion tools
5.  Embedded firmware

Recommended execution order:

data_acquisition/ ↓ preprocessing/ ↓ feature_extraction/ ↓ training/ ↓
evaluation/ ↓ deployment/

------------------------------------------------------------------------

## 11. Methodological Contributions

This methodology introduces:

-   Low-cost intelligent monitoring of biological cultures
-   Multimodal fusion for growth phase classification
-   Edge AI deployment for real-time inference
-   Non-invasive monitoring strategy

------------------------------------------------------------------------

## 12. Limitations

-   Dataset limited to controlled laboratory conditions
-   Species-specific calibration required
-   Sensitivity to extreme illumination changes

Future work includes IoT integration and adaptive environmental control.
